# Registry

## 1. Introduction

Registry is a platform that catches spatial records using pycsw, classifies them
in user-defined catalogs using Elasticsearch and store its image with Mapproxy.
Registry allows the user to separate spatial data in catalogs but search on all
of them at the same time. Once a layer is added into registry, the user is able
to retreive metadata, mapproxy config or thumbnail by hitting different
endpoints.

Records could be defined as a list of descriptive information. For registry, we
can describe records as a collection of geospatial metadata. Each record has
metadata classified and organized within specific keys, i.e. bounding box,
source, title, among others. For each server, we can retreive these records
using different methods. For registry, the user must have its records stored in
xml files. Each file must specify the interfaces and bindings defined by the
OGC standards.

Please refer to http://www.opengeospatial.org/standards/cat for more information.

## 2. Requirements

**Elasticsearch:** Registry has been tested with versions 1.7.5 and 5.0. Please
refer to
https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html
for elasticsearch installation.

## 3. Usage

Registry is written in python and uses Django framework. First, is necessary
to configure the pycsw database.

	python registry.py pycsw -c setup_db

Then, start the server

	python registry.py runserver

Then, you need to start elasticsearch search engine. You can verify if
elasticsearch is running, executing the following command:

	elasticsearch -v

By default, the server will listen in port 8000. Depending on the request
method, Registry will process each received request differently. The user is
free to use its own software, like Paw, postman or curl (if you are a Terminal
ninja) to generate requests.

Now, suppose we have 200 records separated in two files of 100, named xml_1.xml
and xml_2.xml. We want to store each file in two separated catalogs. First is
necessary to create the catalogs for elasticsearch generating the following
request. We will use catalog_1 and catalog_2 catalog names.

	curl -XPUT http://localhost:8000/catalog/catalog_1/csw

to create catalog_1 and

	curl -XPUT http://localhost:8000/catalog/catalog_2/csw

to create the second catalog. Note that to create catalogs we use the PUT
request method. For each request, we will receive a status code of 200 and
the 'Catalog_X has been created succesfully' 

Second, we need to store the records. For each file, we execute the following
requests.

	curl -XPOST http://localhost:8000/catalog/catalog_1/csw -d @xml_1.xml

	curl -XPOST http://localhost:8000/catalog/catalog_2/csw -d @xml_2.xml

The server will use pycsw to parse the records within the xml file defined in
the payload. Each record will be stored into the pycsw database and indexed
into elasticsearch. It is important to note that pycsw created an alphanumerical
identifier for each record.

Registry comes with an api client to retreive metadata from elasticsearch. Is
possible to query searches applying different constraints. For instance, we
can search by time, or search by date. The output format will be json. If you
want to query for catalog_1 you need to execute the following request.

	curl -XGET http://localhost:8000/catalog/catalog_1/api

For all catalogs

	curl -XGET http://localhost:8000/api

Mapproxy is a proxy server which stores in a cache geospatial data from remote
web services. Registry takes advantage of this service, enabling the user to
grab additional information, like images. For instance, when hitting the
following endpoint

	curl -XGET http://localhost:8000/layer/<layer_uuid>.yml

where <layer_uuid> corresponds to the record identifier generated by pycsw,
Registry produces a configuration file in yaml format, that is required by
Mapproxy. Now when executing the following request

	curl -XGET http://localhost:8000/layer/<layer_uuid>

Registry generates the configuration file for the given record and creates a
Mapproxy server instance within Registry, where is possible to use Mapproxy
features as a standalone server. Another feature of Registry is to generate a
record thumbnail, executing the following request.

	curl -XGET http://localhost:8000/layer/<layer_uuid>.png

Registry, will create the mapproxy configuration file, run a mapproxy instance,
and finally execute an image query to the remote web server, that is specified
within the record metadata to get the image thumbnail, that will be returned by
Registry.

## 4. Deployment

Basically, Registry needs a elasticsearch backend in order to work properly. In
deployment, the administrator is free to install both registry and elasticsearch
within the same node server. This project is developed using the django 12
factor pattern. Defining the url for elasticsearch using the
```REGISTRY_SEARCH_URL``` environment variable, we connect registry to  a remote
elasticsearch server previously configured. Same setting could be applied to the
database. By default, registry uses sqlite as the database backend. However,
modifying the environment variable ```REGISTRY_DATABASE_URL```, it is possible
to point to a previously setup pycsw database. Please refer to
http://docs.pycsw.org/en/stable/administration.html for more database support in
pycsw.

In the ```docker-compose.yml``` file, we emulate a deployment environment for
registry within a local computer. Using docker, we create separated instances
for each elasticsearch and postgres, and link registry to each service using
environment variables. For registry, we create three separate instances. These
instances are connected to nginx configured as a load balancer. You can view the
nginx settings in the ```docker/nginx/config.conf``` file.


## 5. Elasticsearch performance considerations

### Elasticsearch cluster setup.

In order to make elasticsearch have a good response time when search queries are
performed, it is important to take into account the Elasticsearch heap size and
the number of nodes that elasticsearch will have. 

**Heap size:** The default installation of Elasticsearch is configured with a
1 GB heap. This number is usually too small. When a lot of documents (generally
more than 500 thousand documents) are indexed in elasticsearch, search queries
take around 2 seconds to return the response. It is recommended to increase
heap size up to half of the node RAM size. Refer to
https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html for
more information.

**Number of nodes:** This represents the number of processes connected to the
elasticsearch cluster. Index is split into multiple elements known as shards
within the node cluster. The more nodes, the more efficient will be the search
response in terms of performance. However, it is important to increase the number
of shards for an index. Having multiple nodes with a small shard number, it will
not have effect in search response time.

### REGISTRY_MAPPING_PRECISION

This parameter may be used instead of tree_levels to set an appropriate value
for the ```tree_levels``` parameter. The value specifies the desired precision
and Elasticsearch will calculate the best tree_levels value to honor this
precision. The value should be a number followed by `m` distance unit.

Elasticsearch uses the paths in the prefix tree as terms in the index and in
queries. The higher the levels is (and thus the precision), the more terms are
generated. Of course, calculating the terms, keeping them in memory, and storing
them on disk all have a price. Especially with higher tree levels, indices can
become extremely large even with a modest amount of data. Additionally, the size
of the features also matters. Big, complex polygons can take up a lot of space
at higher tree levels. Which setting is right depends on the use case. Generally
one trades off accuracy against index size and query performance.

The defaults in Elasticsearch for both implementations are a compromise between
index size and a reasonable level of precision of 50m at the equator. This
allows for indexing tens of millions of shapes without overly bloating the
resulting index too much relative to the input size.

So take care settings low `REGISTRY_MAPPING_PRECISION` because at the moment of
sending Layers to Elasticsearch it will become slow.

**Source.** https://github.com/cga-harvard/HHypermap/
